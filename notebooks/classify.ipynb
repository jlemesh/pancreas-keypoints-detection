{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def load_dataset(extract_func):\n",
    "    data = []\n",
    "    labels = []\n",
    "    \n",
    "    tumor_path = '../data/preprocessed_class/tumor/'\n",
    "    healthy_path = '../data/preprocessed_class/pancreas/'\n",
    "    \n",
    "    for image_path in os.listdir(tumor_path):\n",
    "        image = cv2.imread(os.path.join(tumor_path, image_path))\n",
    "        if image is not None:\n",
    "            descriptors = extract_func(image)\n",
    "            if descriptors is not None:\n",
    "                data.append(descriptors.flatten())\n",
    "                labels.append(1)  # 1 for tumor\n",
    "    \n",
    "    for image_path in os.listdir(healthy_path):\n",
    "        image = cv2.imread(os.path.join(healthy_path, image_path))\n",
    "        if image is not None:\n",
    "            descriptors = extract_func(image)\n",
    "            if descriptors is not None:\n",
    "                data.append(descriptors.flatten())\n",
    "                labels.append(0)  # 0 for pancreas\n",
    "    \n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract SIFT features from an image\n",
    "def extract_sift_features(image, target_shape=(128,128)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create(nfeatures=0, nOctaveLayers=21, contrastThreshold=0.0, edgeThreshold=7, sigma=9.5)\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray, None)\n",
    "    \n",
    "    if descriptors is not None:\n",
    "        if descriptors.shape[0] < target_shape[0]:\n",
    "            # Zero-padding if descriptors are shorter\n",
    "            descriptors = np.pad(descriptors, ((0, target_shape[0] - descriptors.shape[0]), (0, 0)), 'constant')\n",
    "        elif descriptors.shape[0] > target_shape[0]:\n",
    "            # Resize if descriptors are longer\n",
    "            descriptors = cv2.resize(descriptors, (target_shape[1], target_shape[0]))\n",
    "    else:\n",
    "      descriptors = np.zeros((128,128))\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_surf_features(image, target_shape=(128,64)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create a SURF object with specified parameters\n",
    "    surf = cv2.xfeatures2d.SURF_create(hessianThreshold=10, nOctaves=2, nOctaveLayers=4, extended=False, upright=True)\n",
    "    \n",
    "    # Detect and compute SURF keypoints and descriptors\n",
    "    keypoints, descriptors = surf.detectAndCompute(gray, None)\n",
    "    \n",
    "    if descriptors is not None:\n",
    "        if descriptors.shape[0] < target_shape[0]:\n",
    "            # Zero-padding if descriptors are shorter\n",
    "            descriptors = np.pad(descriptors, ((0, target_shape[0] - descriptors.shape[0]), (0, 0)), 'constant')\n",
    "        elif descriptors.shape[0] > target_shape[0]:\n",
    "            # Resize if descriptors are longer\n",
    "            descriptors = cv2.resize(descriptors, (target_shape[1], target_shape[0]))\n",
    "    else:\n",
    "      descriptors = np.zeros(target_shape)\n",
    "\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fast_features(image, target_shape=(32,32)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create a FAST object with specified parameters\n",
    "    fast = cv2.FastFeatureDetector_create(threshold=3, nonmaxSuppression=True, type=0)\n",
    "    \n",
    "    # Detect FAST keypoints\n",
    "    keypoints = fast.detect(gray, None)\n",
    "    \n",
    "    # Compute descriptors (using ORB as an example, you can use any descriptor method)\n",
    "    orb = cv2.ORB_create()\n",
    "    keypoints, descriptors = orb.compute(gray, keypoints)\n",
    "    \n",
    "    if descriptors is not None:\n",
    "        if descriptors.shape[0] < target_shape[0]:\n",
    "            # Zero-padding if descriptors are shorter\n",
    "            descriptors = np.pad(descriptors, ((0, target_shape[0] - descriptors.shape[0]), (0, 0)), 'constant')\n",
    "        elif descriptors.shape[0] > target_shape[0]:\n",
    "            # Resize if descriptors are longer\n",
    "            descriptors = cv2.resize(descriptors, (target_shape[1], target_shape[0]))\n",
    "    else:\n",
    "      descriptors = np.zeros(target_shape)\n",
    "    \n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_orb_features(image, target_shape=(512,32)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create an ORB object with specified parameters\n",
    "    orb = cv2.ORB_create(nfeatures=500, scaleFactor=1.03, nlevels=2, edgeThreshold=21, firstLevel=0, WTA_K=2, scoreType=0, patchSize=31, fastThreshold=0)\n",
    "    \n",
    "    # Detect ORB keypoints and compute descriptors\n",
    "    keypoints, descriptors = orb.detectAndCompute(gray, None)\n",
    "    \n",
    "    if descriptors is not None:\n",
    "        if descriptors.shape[0] < target_shape[0]:\n",
    "            # Zero-padding if descriptors are shorter\n",
    "            descriptors = np.pad(descriptors, ((0, target_shape[0] - descriptors.shape[0]), (0, 0)), 'constant')\n",
    "        elif descriptors.shape[0] > target_shape[0]:\n",
    "            # Resize if descriptors are longer\n",
    "            descriptors = cv2.resize(descriptors, (target_shape[1], target_shape[0]))\n",
    "    else:\n",
    "      descriptors = np.zeros(target_shape)\n",
    "\n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_brisk_features(image, target_shape=(256,64)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create a BRISK object with specified parameters\n",
    "    brisk = cv2.BRISK_create(0, 1, 1.2)\n",
    "    \n",
    "    # Detect and compute BRISK keypoints and descriptors\n",
    "    keypoints, descriptors = brisk.detectAndCompute(gray, None)\n",
    "    \n",
    "    if descriptors is not None:\n",
    "        if descriptors.shape[0] < target_shape[0]:\n",
    "            # Zero-padding if descriptors are shorter\n",
    "            descriptors = np.pad(descriptors, ((0, target_shape[0] - descriptors.shape[0]), (0, 0)), 'constant')\n",
    "        elif descriptors.shape[0] > target_shape[0]:\n",
    "            # Resize if descriptors are longer\n",
    "            descriptors = cv2.resize(descriptors, (target_shape[1], target_shape[0]))\n",
    "    else:\n",
    "      descriptors = np.zeros(target_shape)\n",
    "    \n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_kaze_features(image, target_shape=(128,128)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create a KAZE object with specified parameters\n",
    "    kaze = cv2.KAZE_create(extended=True, upright=False, threshold=0.0, nOctaves=4, nOctaveLayers=1, diffusivity=1)\n",
    "    \n",
    "    # Detect and compute KAZE keypoints and descriptors\n",
    "    keypoints, descriptors = kaze.detectAndCompute(gray, None)\n",
    "    \n",
    "    if descriptors is not None:\n",
    "        if descriptors.shape[0] < target_shape[0]:\n",
    "            # Zero-padding if descriptors are shorter\n",
    "            descriptors = np.pad(descriptors, ((0, target_shape[0] - descriptors.shape[0]), (0, 0)), 'constant')\n",
    "        elif descriptors.shape[0] > target_shape[0]:\n",
    "            # Resize if descriptors are longer\n",
    "            descriptors = cv2.resize(descriptors, (target_shape[1], target_shape[0]))\n",
    "    else:\n",
    "      descriptors = np.zeros(target_shape)\n",
    "      \n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_akaze_features(image, target_shape=(128,16)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create an AKAZE object with specified parameters\n",
    "    akaze = cv2.AKAZE_create(descriptor_type=5, descriptor_size=128, descriptor_channels=3, threshold=0.0, nOctaves=1, nOctaveLayers=1, diffusivity=0)\n",
    "    \n",
    "    # Detect and compute AKAZE keypoints and descriptors\n",
    "    keypoints, descriptors = akaze.detectAndCompute(gray, None)\n",
    "    \n",
    "    if descriptors is not None:\n",
    "        if descriptors.shape[0] < target_shape[0]:\n",
    "            # Zero-padding if descriptors are shorter\n",
    "            descriptors = np.pad(descriptors, ((0, target_shape[0] - descriptors.shape[0]), (0, 0)), 'constant')\n",
    "        elif descriptors.shape[0] > target_shape[0]:\n",
    "            # Resize if descriptors are longer\n",
    "            descriptors = cv2.resize(descriptors, (target_shape[1], target_shape[0]))\n",
    "    else:\n",
    "      descriptors = np.zeros(target_shape)\n",
    "    \n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_agast_features(image, target_shape=(32,32)):\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Create an AGAST object with specified parameters\n",
    "    agast = cv2.AgastFeatureDetector_create(threshold=7, nonmaxSuppression=False, type=0)\n",
    "    \n",
    "    # Detect AGAST keypoints\n",
    "    keypoints = agast.detect(gray, None)\n",
    "    \n",
    "    # Compute descriptors using BRIEF\n",
    "    brief = cv2.xfeatures2d.BriefDescriptorExtractor_create()\n",
    "    keypoints, descriptors = brief.compute(gray, keypoints)\n",
    "    \n",
    "    if descriptors is not None:\n",
    "        if descriptors.shape[0] < target_shape[0]:\n",
    "            # Zero-padding if descriptors are shorter\n",
    "            descriptors = np.pad(descriptors, ((0, target_shape[0] - descriptors.shape[0]), (0, 0)), 'constant')\n",
    "        elif descriptors.shape[0] > target_shape[0]:\n",
    "            # Resize if descriptors are longer\n",
    "            descriptors = cv2.resize(descriptors, (target_shape[1], target_shape[0]))\n",
    "    else:\n",
    "      descriptors = np.zeros(target_shape)\n",
    "    \n",
    "    return descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform(data, labels):\n",
    "  print(f\"dataset: {data.shape},\")\n",
    "  # Split the dataset into training and testing sets\n",
    "  X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "  # Create a Support Vector Machine (SVM) classifier\n",
    "  classifier = SVC()\n",
    "\n",
    "  # Define the parameter grid for grid search\n",
    "  param_grid = {\n",
    "      'C': [0.1, 1, 10, 100],\n",
    "      'kernel': ['linear', 'rbf', 'poly'],\n",
    "      'gamma': ['scale', 'auto'],\n",
    "  }\n",
    "\n",
    "  # Use GridSearchCV for hyperparameter tuning\n",
    "  grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy', verbose=1)\n",
    "  grid_search.fit(X_train, y_train)\n",
    "\n",
    "  # Get the best hyperparameters\n",
    "  best_params = grid_search.best_params_\n",
    "  print(f\"Best hyperparameters: {best_params}\")\n",
    "\n",
    "  # Train the classifier on the entire training set with the best hyperparameters\n",
    "  best_classifier = grid_search.best_estimator_\n",
    "  best_classifier.fit(X_train, y_train)\n",
    "\n",
    "  # Make predictions on the test set\n",
    "  predictions = best_classifier.predict(X_test)\n",
    "\n",
    "  # Evaluate the model\n",
    "  accuracy = accuracy_score(y_test, predictions)\n",
    "  print(f\"Accuracy on the test set: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SIFT\")\n",
    "data, labels = load_dataset(extract_sift_features)\n",
    "perform(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"SURF\")\n",
    "data, labels = load_dataset(extract_surf_features)\n",
    "perform(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"FAST\")\n",
    "data, labels = load_dataset(extract_fast_features)\n",
    "perform(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ORB\")\n",
    "data, labels = load_dataset(extract_orb_features)\n",
    "perform(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"BRISK\")\n",
    "data, labels = load_dataset(extract_brisk_features)\n",
    "perform(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"KAZE\")\n",
    "data, labels = load_dataset(extract_kaze_features)\n",
    "perform(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AKAZE\")\n",
    "data, labels = load_dataset(extract_akaze_features)\n",
    "perform(data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AGAST\")\n",
    "data, labels = load_dataset(extract_agast_features)\n",
    "perform(data, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv_built",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
